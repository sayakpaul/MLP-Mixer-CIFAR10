{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rLEpvdDWzfJu"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comes from \n",
    "# https://github.com/GoogleCloudPlatform/keras-idiomatic-programmer/tree/master/zoo\n",
    "!wget -q https://git.io/Jshxv -O resnet20.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lIYdn1woOS1n",
    "outputId": "d6a3872e-734e-4674-b8a0-0290d85d98f5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK\n",
      "Your GPUs will likely run quickly with dtype policy mixed_float16 as they all have compute capability of at least 7.0\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import layers\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import resnet20\n",
    "\n",
    "# Only enable this for tensor-core GPUs\n",
    "from tensorflow.keras import mixed_precision\n",
    "mixed_precision.set_global_policy(\"mixed_float16\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PQv9hhdJz3GK",
    "outputId": "83bede46-b83c-48fd-be08-0fab7db48153"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3')\n",
      "Number of accelerators:  4\n"
     ]
    }
   ],
   "source": [
    "try: \n",
    "    tpu = None\n",
    "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver() \n",
    "    tf.config.experimental_connect_to_cluster(tpu)\n",
    "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "    strategy = tf.distribute.TPUStrategy(tpu)\n",
    "except ValueError: \n",
    "    strategy = tf.distribute.MirroredStrategy() \n",
    "\n",
    "print(\"Number of accelerators: \", strategy.num_replicas_in_sync)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F86Hxyhe0t6z"
   },
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "tpEtfs_zQ1aw"
   },
   "outputs": [],
   "source": [
    "RESIZE_TO = 72\n",
    "EPOCHS = 100\n",
    "BATCH_SIZE = 512 * strategy.num_replicas_in_sync"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pl7NBpaX0vmZ"
   },
   "source": [
    "## Dataset Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "1lbRgIu0BbTF"
   },
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "t6qEXvcVR7ZJ"
   },
   "outputs": [],
   "source": [
    "def get_augmentation_layers():\n",
    "    data_augmentation = keras.Sequential(\n",
    "        [\n",
    "            layers.experimental.preprocessing.Normalization(),\n",
    "            layers.experimental.preprocessing.Resizing(RESIZE_TO, RESIZE_TO),\n",
    "            layers.experimental.preprocessing.RandomFlip(\"horizontal\"),\n",
    "            layers.experimental.preprocessing.RandomRotation(factor=0.02),\n",
    "            layers.experimental.preprocessing.RandomZoom(\n",
    "                height_factor=0.2, width_factor=0.2\n",
    "            ),\n",
    "        ],\n",
    "        name=\"data_augmentation\",\n",
    "    )\n",
    "    # Compute the mean and the variance of the training data for normalization.\n",
    "    data_augmentation.layers[0].adapt(x_train)\n",
    "    \n",
    "    return data_augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pLWzoSyL3AlB"
   },
   "source": [
    "## ResNet20 Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "_8cOi71NDCPC"
   },
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    n = 2\n",
    "    depth = n * 9 + 2\n",
    "    n_blocks = ((depth - 2) // 9) - 1\n",
    "\n",
    "    # The input tensor\n",
    "    inputs = layers.Input(shape=(32, 32, 3))\n",
    "    data_augmentation = get_augmentation_layers()\n",
    "    augmented = data_augmentation(inputs)\n",
    "    \n",
    "    # The Stem Convolution Group\n",
    "    x = resnet20.stem(augmented)\n",
    "\n",
    "    # The learner\n",
    "    x = resnet20.learner(x, n_blocks)\n",
    "\n",
    "    # The Classifier for 10 classes\n",
    "    outputs = resnet20.classifier(x, 10)\n",
    "\n",
    "    # Instantiate the Model\n",
    "    model = tf.keras.Model(inputs, outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "8dDTVVfmToYj"
   },
   "outputs": [],
   "source": [
    "def create_mlp_mixer():\n",
    "    data_augmentation = get_augmentation_layers()\n",
    "    \n",
    "    inputs = layers.Input(shape=(32, 32, 3))\n",
    "    augmented = data_augmentation(inputs)\n",
    "    outputs = mlp_mixer(augmented, NUM_MIXER_LAYERS,\n",
    "                        PATCH_SIZE, HIDDEN_SIZE, \n",
    "                        MLP_SEQ_DIM, MLP_CHANNEL_DIM)\n",
    "    return tf.keras.Model(inputs, outputs, name=\"mlp_mixer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "wzogB6HoVh5J"
   },
   "outputs": [],
   "source": [
    "def run_experiment(model):\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=0.001 * strategy.num_replicas_in_sync)\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss=\"sparse_categorical_crossentropy\",\n",
    "        metrics=[\"accuracy\"]\n",
    "    )\n",
    "\n",
    "    checkpoint_filepath = \"/tmp/checkpoint\"\n",
    "    checkpoint_callback = keras.callbacks.ModelCheckpoint(\n",
    "        checkpoint_filepath,\n",
    "        monitor=\"val_accuracy\",\n",
    "        save_best_only=True,\n",
    "        save_weights_only=True,\n",
    "    )\n",
    "\n",
    "    history = model.fit(\n",
    "        x=x_train,\n",
    "        y=y_train,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        epochs=EPOCHS,\n",
    "        validation_split=0.1,\n",
    "        callbacks=[checkpoint_callback],\n",
    "    )\n",
    "\n",
    "    model.load_weights(checkpoint_filepath)\n",
    "    _, top_1_accuracy = model.evaluate(x_test, y_test)\n",
    "    print(f\"Test accuracy: {round(top_1_accuracy * 100, 2)}%\")\n",
    "    \n",
    "    return history, model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_X6YN4B2lGrO",
    "outputId": "b58f5b40-e70a-4bce-a14c-7e5a3a35dfb8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "Epoch 1/100\n",
      "INFO:tensorflow:batch_all_reduce: 64 all-reduces with algorithm = nccl, num_packs = 1\n",
      "INFO:tensorflow:batch_all_reduce: 64 all-reduces with algorithm = nccl, num_packs = 1\n",
      "22/22 [==============================] - 58s 518ms/step - loss: 2.8895 - accuracy: 0.2477 - val_loss: 3.0733 - val_accuracy: 0.1538\n",
      "Epoch 2/100\n",
      "22/22 [==============================] - 5s 233ms/step - loss: 2.3179 - accuracy: 0.4024 - val_loss: 3.2545 - val_accuracy: 0.1268\n",
      "Epoch 3/100\n",
      "22/22 [==============================] - 5s 234ms/step - loss: 1.9461 - accuracy: 0.4868 - val_loss: 3.2244 - val_accuracy: 0.1538\n",
      "Epoch 4/100\n",
      "22/22 [==============================] - 5s 234ms/step - loss: 1.6965 - accuracy: 0.5388 - val_loss: 3.1525 - val_accuracy: 0.1690\n",
      "Epoch 5/100\n",
      "22/22 [==============================] - 5s 233ms/step - loss: 1.5551 - accuracy: 0.5697 - val_loss: 3.3099 - val_accuracy: 0.1242\n",
      "Epoch 6/100\n",
      "22/22 [==============================] - 5s 233ms/step - loss: 1.4341 - accuracy: 0.6018 - val_loss: 3.5459 - val_accuracy: 0.1132\n",
      "Epoch 7/100\n",
      "22/22 [==============================] - 5s 233ms/step - loss: 1.3294 - accuracy: 0.6328 - val_loss: 4.0919 - val_accuracy: 0.0970\n",
      "Epoch 8/100\n",
      "22/22 [==============================] - 5s 233ms/step - loss: 1.2513 - accuracy: 0.6542 - val_loss: 3.8851 - val_accuracy: 0.1134\n",
      "Epoch 9/100\n",
      "22/22 [==============================] - 5s 233ms/step - loss: 1.2085 - accuracy: 0.6662 - val_loss: 3.9913 - val_accuracy: 0.0978\n",
      "Epoch 10/100\n",
      "22/22 [==============================] - 5s 233ms/step - loss: 1.1527 - accuracy: 0.6882 - val_loss: 3.8399 - val_accuracy: 0.1378\n",
      "Epoch 11/100\n",
      "22/22 [==============================] - 5s 233ms/step - loss: 1.1030 - accuracy: 0.7010 - val_loss: 4.5212 - val_accuracy: 0.0954\n",
      "Epoch 12/100\n",
      "22/22 [==============================] - 5s 233ms/step - loss: 1.0574 - accuracy: 0.7179 - val_loss: 3.8954 - val_accuracy: 0.1132\n",
      "Epoch 13/100\n",
      "22/22 [==============================] - 5s 233ms/step - loss: 1.0240 - accuracy: 0.7250 - val_loss: 3.9965 - val_accuracy: 0.1644\n",
      "Epoch 14/100\n",
      "22/22 [==============================] - 5s 234ms/step - loss: 1.0116 - accuracy: 0.7325 - val_loss: 4.0552 - val_accuracy: 0.1530\n",
      "Epoch 15/100\n",
      "22/22 [==============================] - 5s 233ms/step - loss: 0.9796 - accuracy: 0.7420 - val_loss: 3.8102 - val_accuracy: 0.1296\n",
      "Epoch 16/100\n",
      "22/22 [==============================] - 5s 233ms/step - loss: 0.9533 - accuracy: 0.7491 - val_loss: 4.5141 - val_accuracy: 0.1330\n",
      "Epoch 17/100\n",
      "22/22 [==============================] - 5s 233ms/step - loss: 0.9172 - accuracy: 0.7592 - val_loss: 4.0465 - val_accuracy: 0.1594\n",
      "Epoch 18/100\n",
      "22/22 [==============================] - 5s 233ms/step - loss: 0.9161 - accuracy: 0.7590 - val_loss: 4.7068 - val_accuracy: 0.1568\n",
      "Epoch 19/100\n",
      "22/22 [==============================] - 5s 233ms/step - loss: 0.8902 - accuracy: 0.7731 - val_loss: 4.3082 - val_accuracy: 0.1582\n",
      "Epoch 20/100\n",
      "22/22 [==============================] - 5s 233ms/step - loss: 0.8631 - accuracy: 0.7793 - val_loss: 4.3877 - val_accuracy: 0.1954\n",
      "Epoch 21/100\n",
      "22/22 [==============================] - 5s 233ms/step - loss: 0.8496 - accuracy: 0.7810 - val_loss: 3.0302 - val_accuracy: 0.2708\n",
      "Epoch 22/100\n",
      "22/22 [==============================] - 5s 233ms/step - loss: 0.8320 - accuracy: 0.7881 - val_loss: 2.6477 - val_accuracy: 0.2192\n",
      "Epoch 23/100\n",
      "22/22 [==============================] - 5s 233ms/step - loss: 0.8437 - accuracy: 0.7856 - val_loss: 2.6313 - val_accuracy: 0.3550\n",
      "Epoch 24/100\n",
      "22/22 [==============================] - 5s 233ms/step - loss: 0.8034 - accuracy: 0.7997 - val_loss: 3.6799 - val_accuracy: 0.1796\n",
      "Epoch 25/100\n",
      "22/22 [==============================] - 5s 234ms/step - loss: 0.8055 - accuracy: 0.7990 - val_loss: 2.2842 - val_accuracy: 0.3662\n",
      "Epoch 26/100\n",
      "22/22 [==============================] - 5s 233ms/step - loss: 0.7868 - accuracy: 0.8062 - val_loss: 2.4158 - val_accuracy: 0.3930\n",
      "Epoch 27/100\n",
      "22/22 [==============================] - 5s 233ms/step - loss: 0.7888 - accuracy: 0.8047 - val_loss: 1.8132 - val_accuracy: 0.5324\n",
      "Epoch 28/100\n",
      "22/22 [==============================] - 5s 233ms/step - loss: 0.7773 - accuracy: 0.8099 - val_loss: 1.9030 - val_accuracy: 0.4626\n",
      "Epoch 29/100\n",
      "22/22 [==============================] - 5s 233ms/step - loss: 0.7697 - accuracy: 0.8125 - val_loss: 1.9642 - val_accuracy: 0.4180\n",
      "Epoch 30/100\n",
      "22/22 [==============================] - 5s 233ms/step - loss: 0.7447 - accuracy: 0.8205 - val_loss: 2.3287 - val_accuracy: 0.3752\n",
      "Epoch 31/100\n",
      "22/22 [==============================] - 5s 233ms/step - loss: 0.7633 - accuracy: 0.8116 - val_loss: 1.4522 - val_accuracy: 0.5998\n",
      "Epoch 32/100\n",
      "22/22 [==============================] - 5s 233ms/step - loss: 0.7595 - accuracy: 0.8159 - val_loss: 1.5528 - val_accuracy: 0.5964\n",
      "Epoch 33/100\n",
      "22/22 [==============================] - 5s 233ms/step - loss: 0.7354 - accuracy: 0.8215 - val_loss: 1.5783 - val_accuracy: 0.5466\n",
      "Epoch 34/100\n",
      "22/22 [==============================] - 5s 233ms/step - loss: 0.7256 - accuracy: 0.8260 - val_loss: 1.8934 - val_accuracy: 0.5214\n",
      "Epoch 35/100\n",
      "22/22 [==============================] - 5s 233ms/step - loss: 0.7240 - accuracy: 0.8281 - val_loss: 1.1696 - val_accuracy: 0.6710\n",
      "Epoch 36/100\n",
      "22/22 [==============================] - 5s 233ms/step - loss: 0.7226 - accuracy: 0.8285 - val_loss: 1.2231 - val_accuracy: 0.6644\n",
      "Epoch 37/100\n",
      "22/22 [==============================] - 5s 233ms/step - loss: 0.7161 - accuracy: 0.8268 - val_loss: 3.2667 - val_accuracy: 0.3382\n",
      "Epoch 38/100\n",
      "22/22 [==============================] - 5s 233ms/step - loss: 0.7003 - accuracy: 0.8351 - val_loss: 1.6188 - val_accuracy: 0.5732\n",
      "Epoch 39/100\n",
      "22/22 [==============================] - 5s 233ms/step - loss: 0.7040 - accuracy: 0.8343 - val_loss: 1.2605 - val_accuracy: 0.6536\n",
      "Epoch 40/100\n",
      "22/22 [==============================] - 5s 233ms/step - loss: 0.7069 - accuracy: 0.8333 - val_loss: 0.9645 - val_accuracy: 0.7452\n",
      "Epoch 41/100\n",
      "22/22 [==============================] - 5s 233ms/step - loss: 0.6801 - accuracy: 0.8449 - val_loss: 1.3654 - val_accuracy: 0.5862\n",
      "Epoch 42/100\n",
      "22/22 [==============================] - 5s 233ms/step - loss: 0.6876 - accuracy: 0.8414 - val_loss: 1.2853 - val_accuracy: 0.6494\n",
      "Epoch 43/100\n",
      "22/22 [==============================] - 5s 233ms/step - loss: 0.6864 - accuracy: 0.8390 - val_loss: 1.4284 - val_accuracy: 0.6250\n",
      "Epoch 44/100\n",
      "22/22 [==============================] - 5s 233ms/step - loss: 0.6791 - accuracy: 0.8428 - val_loss: 1.1874 - val_accuracy: 0.6630\n",
      "Epoch 45/100\n",
      "22/22 [==============================] - 5s 233ms/step - loss: 0.6736 - accuracy: 0.8442 - val_loss: 1.1281 - val_accuracy: 0.7032\n",
      "Epoch 46/100\n",
      "22/22 [==============================] - 5s 233ms/step - loss: 0.6659 - accuracy: 0.8494 - val_loss: 1.4277 - val_accuracy: 0.6498\n",
      "Epoch 47/100\n",
      "22/22 [==============================] - 5s 233ms/step - loss: 0.6731 - accuracy: 0.8447 - val_loss: 1.4893 - val_accuracy: 0.6224\n",
      "Epoch 48/100\n",
      "22/22 [==============================] - 5s 234ms/step - loss: 0.6565 - accuracy: 0.8522 - val_loss: 0.9755 - val_accuracy: 0.7476\n",
      "Epoch 49/100\n",
      "22/22 [==============================] - 5s 234ms/step - loss: 0.6657 - accuracy: 0.8471 - val_loss: 1.3116 - val_accuracy: 0.6430\n",
      "Epoch 50/100\n",
      "22/22 [==============================] - 5s 233ms/step - loss: 0.6625 - accuracy: 0.8508 - val_loss: 0.9701 - val_accuracy: 0.7456\n",
      "Epoch 51/100\n",
      "22/22 [==============================] - 5s 233ms/step - loss: 0.6653 - accuracy: 0.8470 - val_loss: 0.9376 - val_accuracy: 0.7550\n",
      "Epoch 52/100\n",
      "22/22 [==============================] - 5s 233ms/step - loss: 0.6570 - accuracy: 0.8532 - val_loss: 1.2908 - val_accuracy: 0.6598\n",
      "Epoch 53/100\n",
      "22/22 [==============================] - 5s 233ms/step - loss: 0.6508 - accuracy: 0.8541 - val_loss: 1.2992 - val_accuracy: 0.6598\n",
      "Epoch 54/100\n",
      "22/22 [==============================] - 5s 233ms/step - loss: 0.6407 - accuracy: 0.8581 - val_loss: 1.1663 - val_accuracy: 0.6976\n",
      "Epoch 55/100\n",
      "22/22 [==============================] - 5s 233ms/step - loss: 0.6528 - accuracy: 0.8543 - val_loss: 1.2175 - val_accuracy: 0.6824\n",
      "Epoch 56/100\n",
      "22/22 [==============================] - 5s 234ms/step - loss: 0.6307 - accuracy: 0.8626 - val_loss: 1.4997 - val_accuracy: 0.6164\n",
      "Epoch 57/100\n",
      "22/22 [==============================] - 5s 233ms/step - loss: 0.6298 - accuracy: 0.8612 - val_loss: 1.9246 - val_accuracy: 0.5478\n",
      "Epoch 58/100\n",
      "22/22 [==============================] - 5s 233ms/step - loss: 0.6223 - accuracy: 0.8642 - val_loss: 1.3326 - val_accuracy: 0.6674\n",
      "Epoch 59/100\n",
      "22/22 [==============================] - 5s 233ms/step - loss: 0.6224 - accuracy: 0.8639 - val_loss: 1.2750 - val_accuracy: 0.6996\n",
      "Epoch 60/100\n",
      "22/22 [==============================] - 5s 233ms/step - loss: 0.6284 - accuracy: 0.8618 - val_loss: 1.4733 - val_accuracy: 0.5954\n",
      "Epoch 61/100\n",
      "22/22 [==============================] - 5s 233ms/step - loss: 0.6321 - accuracy: 0.8598 - val_loss: 0.9613 - val_accuracy: 0.7640\n",
      "Epoch 62/100\n",
      "22/22 [==============================] - 5s 232ms/step - loss: 0.6195 - accuracy: 0.8637 - val_loss: 1.1686 - val_accuracy: 0.6954\n",
      "Epoch 63/100\n",
      "22/22 [==============================] - 5s 233ms/step - loss: 0.6226 - accuracy: 0.8621 - val_loss: 1.9571 - val_accuracy: 0.6158\n",
      "Epoch 64/100\n",
      "22/22 [==============================] - 5s 234ms/step - loss: 0.6040 - accuracy: 0.8689 - val_loss: 1.4386 - val_accuracy: 0.6516\n",
      "Epoch 65/100\n",
      "22/22 [==============================] - 5s 234ms/step - loss: 0.6114 - accuracy: 0.8667 - val_loss: 1.1577 - val_accuracy: 0.7036\n",
      "Epoch 66/100\n",
      "22/22 [==============================] - 5s 233ms/step - loss: 0.6157 - accuracy: 0.8677 - val_loss: 1.0530 - val_accuracy: 0.7352\n",
      "Epoch 67/100\n",
      "22/22 [==============================] - 5s 233ms/step - loss: 0.6229 - accuracy: 0.8642 - val_loss: 1.1132 - val_accuracy: 0.7218\n",
      "Epoch 68/100\n",
      "22/22 [==============================] - 5s 232ms/step - loss: 0.6219 - accuracy: 0.8627 - val_loss: 1.5752 - val_accuracy: 0.6604\n",
      "Epoch 69/100\n",
      "22/22 [==============================] - 5s 233ms/step - loss: 0.6203 - accuracy: 0.8645 - val_loss: 1.3331 - val_accuracy: 0.6706\n",
      "Epoch 70/100\n",
      "22/22 [==============================] - 5s 233ms/step - loss: 0.6156 - accuracy: 0.8644 - val_loss: 1.1575 - val_accuracy: 0.7274\n",
      "Epoch 71/100\n",
      "22/22 [==============================] - 5s 233ms/step - loss: 0.6130 - accuracy: 0.8668 - val_loss: 1.0526 - val_accuracy: 0.7316\n",
      "Epoch 72/100\n",
      "22/22 [==============================] - 5s 234ms/step - loss: 0.5986 - accuracy: 0.8727 - val_loss: 1.0279 - val_accuracy: 0.7392\n",
      "Epoch 73/100\n",
      "22/22 [==============================] - 5s 233ms/step - loss: 0.6006 - accuracy: 0.8710 - val_loss: 1.1171 - val_accuracy: 0.7422\n",
      "Epoch 74/100\n",
      "22/22 [==============================] - 5s 233ms/step - loss: 0.6016 - accuracy: 0.8725 - val_loss: 1.5893 - val_accuracy: 0.6262\n",
      "Epoch 75/100\n",
      "22/22 [==============================] - 5s 233ms/step - loss: 0.5898 - accuracy: 0.8767 - val_loss: 1.3083 - val_accuracy: 0.7086\n",
      "Epoch 76/100\n",
      "22/22 [==============================] - 5s 233ms/step - loss: 0.6077 - accuracy: 0.8698 - val_loss: 1.0316 - val_accuracy: 0.7360\n",
      "Epoch 77/100\n",
      "22/22 [==============================] - 5s 233ms/step - loss: 0.6069 - accuracy: 0.8690 - val_loss: 1.0951 - val_accuracy: 0.7170\n",
      "Epoch 78/100\n",
      "22/22 [==============================] - 5s 233ms/step - loss: 0.5868 - accuracy: 0.8784 - val_loss: 1.2917 - val_accuracy: 0.7154\n",
      "Epoch 79/100\n",
      "22/22 [==============================] - 5s 233ms/step - loss: 0.5848 - accuracy: 0.8785 - val_loss: 0.8497 - val_accuracy: 0.7916\n",
      "Epoch 80/100\n",
      "22/22 [==============================] - 5s 233ms/step - loss: 0.5877 - accuracy: 0.8772 - val_loss: 1.3510 - val_accuracy: 0.6852\n",
      "Epoch 81/100\n",
      "22/22 [==============================] - 5s 233ms/step - loss: 0.5880 - accuracy: 0.8737 - val_loss: 2.7452 - val_accuracy: 0.4996\n",
      "Epoch 82/100\n",
      "22/22 [==============================] - 5s 233ms/step - loss: 0.5943 - accuracy: 0.8722 - val_loss: 1.2361 - val_accuracy: 0.7322\n",
      "Epoch 83/100\n",
      "22/22 [==============================] - 5s 233ms/step - loss: 0.5902 - accuracy: 0.8750 - val_loss: 1.1805 - val_accuracy: 0.7162\n",
      "Epoch 84/100\n",
      "22/22 [==============================] - 5s 233ms/step - loss: 0.5781 - accuracy: 0.8792 - val_loss: 0.9747 - val_accuracy: 0.7560\n",
      "Epoch 85/100\n",
      "22/22 [==============================] - 5s 233ms/step - loss: 0.5956 - accuracy: 0.8729 - val_loss: 1.2092 - val_accuracy: 0.7164\n",
      "Epoch 86/100\n",
      "22/22 [==============================] - 5s 233ms/step - loss: 0.5794 - accuracy: 0.8798 - val_loss: 1.1518 - val_accuracy: 0.6970\n",
      "Epoch 87/100\n",
      "22/22 [==============================] - 5s 232ms/step - loss: 0.5816 - accuracy: 0.8790 - val_loss: 1.3794 - val_accuracy: 0.6714\n",
      "Epoch 88/100\n",
      "22/22 [==============================] - 5s 234ms/step - loss: 0.5768 - accuracy: 0.8784 - val_loss: 1.1338 - val_accuracy: 0.7216\n",
      "Epoch 89/100\n",
      "22/22 [==============================] - 5s 233ms/step - loss: 0.5701 - accuracy: 0.8832 - val_loss: 1.0746 - val_accuracy: 0.7240\n",
      "Epoch 90/100\n",
      "22/22 [==============================] - 5s 233ms/step - loss: 0.5638 - accuracy: 0.8829 - val_loss: 1.3817 - val_accuracy: 0.6914\n",
      "Epoch 91/100\n",
      "22/22 [==============================] - 5s 232ms/step - loss: 0.5926 - accuracy: 0.8719 - val_loss: 2.1705 - val_accuracy: 0.5756\n",
      "Epoch 92/100\n",
      "22/22 [==============================] - 5s 233ms/step - loss: 0.5792 - accuracy: 0.8788 - val_loss: 1.1941 - val_accuracy: 0.7210\n",
      "Epoch 93/100\n",
      "22/22 [==============================] - 5s 233ms/step - loss: 0.5752 - accuracy: 0.8809 - val_loss: 1.2513 - val_accuracy: 0.7272\n",
      "Epoch 94/100\n",
      "22/22 [==============================] - 5s 233ms/step - loss: 0.5729 - accuracy: 0.8825 - val_loss: 1.8536 - val_accuracy: 0.6096\n",
      "Epoch 95/100\n",
      "22/22 [==============================] - 5s 232ms/step - loss: 0.5790 - accuracy: 0.8781 - val_loss: 1.1499 - val_accuracy: 0.7372\n",
      "Epoch 96/100\n",
      "22/22 [==============================] - 5s 233ms/step - loss: 0.5718 - accuracy: 0.8815 - val_loss: 0.9616 - val_accuracy: 0.7664\n",
      "Epoch 97/100\n",
      "22/22 [==============================] - 5s 233ms/step - loss: 0.5594 - accuracy: 0.8844 - val_loss: 1.1350 - val_accuracy: 0.7158\n",
      "Epoch 98/100\n",
      "22/22 [==============================] - 5s 233ms/step - loss: 0.5578 - accuracy: 0.8843 - val_loss: 2.2543 - val_accuracy: 0.5716\n",
      "Epoch 99/100\n",
      "22/22 [==============================] - 5s 233ms/step - loss: 0.5507 - accuracy: 0.8877 - val_loss: 0.9882 - val_accuracy: 0.7632\n",
      "Epoch 100/100\n",
      "22/22 [==============================] - 5s 233ms/step - loss: 0.5676 - accuracy: 0.8813 - val_loss: 1.2605 - val_accuracy: 0.7100\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.8698 - accuracy: 0.7814\n",
      "Test accuracy: 78.14%\n",
      "INFO:tensorflow:Assets written to: resnet20_cifar10/assets\n"
     ]
    }
   ],
   "source": [
    "with strategy.scope():\n",
    "    resnet20 = get_model()\n",
    "    history, model = run_experiment(resnet20)\n",
    "    model.save(f\"resnet20_cifar10\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.571969"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet20.count_params()/1e6"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "include_colab_link": true,
   "machine_shape": "hm",
   "name": "MLP_Mixer_Training",
   "provenance": []
  },
  "environment": {
   "name": "tf2-gpu.2-4.m65",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-4:m65"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
